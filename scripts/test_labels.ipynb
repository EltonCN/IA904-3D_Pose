{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-body7_pt-body7_420e-256x192-e48f03d0_20230504.pth\n",
      "06/23 16:46:26 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpose\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpose\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "06/23 16:46:29 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "img_path = 'test_image.jpg'   # replace this with your own image path\n",
    "\n",
    "# instantiate the inferencer using the model alias\n",
    "inferencer = MMPoseInferencer('human')\n",
    "\n",
    "# The MMPoseInferencer API employs a lazy inference approach,\n",
    "# creating a prediction generator when given input\n",
    "result_generator = inferencer(img_path, show=True)\n",
    "result = next(result_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob #Search files\n",
    "import json #JSON write\n",
    "import pathlib #Path things\n",
    "import os #Path things\n",
    "import warnings #Modified call\n",
    "from concurrent.futures import ThreadPoolExecutor #Threading\n",
    "from types import MethodType #Modified call\n",
    "from typing import Optional #Modified call\n",
    "\n",
    "import numpy as np #Array operations\n",
    "import imageio #EXR write\n",
    "import tqdm #Progress bar\n",
    "from rich.progress import track #Modified call\n",
    "import mmpose #Feature extractor\n",
    "from mmpose.apis import MMPoseInferencer #Feature extractor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base from MMPoseInferencer.__call__\n",
    "def modified_call(\n",
    "        self,\n",
    "        inputs: mmpose.apis.inferencers.mmpose_inferencer.InputsType,\n",
    "        return_datasamples: bool = False,\n",
    "        batch_size: int = 1,\n",
    "        out_dir: Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ) -> dict:\n",
    "        \"\"\"Call the inferencer.\n",
    "\n",
    "        Args:\n",
    "            inputs (InputsType): Inputs for the inferencer.\n",
    "            return_datasamples (bool): Whether to return results as\n",
    "                :obj:`BaseDataElement`. Defaults to False.\n",
    "            batch_size (int): Batch size. Defaults to 1.\n",
    "            out_dir (str, optional): directory to save visualization\n",
    "                results and predictions. Will be overoden if vis_out_dir or\n",
    "                pred_out_dir are given. Defaults to None\n",
    "            **kwargs: Key words arguments passed to :meth:`preprocess`,\n",
    "                :meth:`forward`, :meth:`visualize` and :meth:`postprocess`.\n",
    "                Each key in kwargs should be in the corresponding set of\n",
    "                ``preprocess_kwargs``, ``forward_kwargs``,\n",
    "                ``visualize_kwargs`` and ``postprocess_kwargs``.\n",
    "\n",
    "        Returns:\n",
    "            dict: Inference and visualization results.\n",
    "        \"\"\"\n",
    "        if out_dir is not None:\n",
    "            if 'vis_out_dir' not in kwargs:\n",
    "                kwargs['vis_out_dir'] = f'{out_dir}/visualizations'\n",
    "            if 'pred_out_dir' not in kwargs:\n",
    "                kwargs['pred_out_dir'] = f'{out_dir}/predictions'\n",
    "        \n",
    "        kwargs = {\n",
    "            key: value\n",
    "            for key, value in kwargs.items()\n",
    "            if key in set.union(self.inferencer.preprocess_kwargs,\n",
    "                                self.inferencer.forward_kwargs,\n",
    "                                self.inferencer.visualize_kwargs,\n",
    "                                self.inferencer.postprocess_kwargs)\n",
    "        }\n",
    "        (\n",
    "            preprocess_kwargs,\n",
    "            forward_kwargs,\n",
    "            visualize_kwargs,\n",
    "            postprocess_kwargs,\n",
    "        ) = self._dispatch_kwargs(**kwargs)\n",
    "\n",
    "        self.inferencer.update_model_visualizer_settings(**kwargs)\n",
    "\n",
    "        # preprocessing\n",
    "        if isinstance(inputs, str) and inputs.startswith('webcam'):\n",
    "            inputs = self.inferencer._get_webcam_inputs(inputs)\n",
    "            batch_size = 1\n",
    "            if not visualize_kwargs.get('show', False):\n",
    "                warnings.warn('The display mode is closed when using webcam '\n",
    "                              'input. It will be turned on automatically.')\n",
    "            visualize_kwargs['show'] = True\n",
    "        else:\n",
    "            inputs = self.inferencer._inputs_to_list(inputs)\n",
    "        self._video_input = self.inferencer._video_input\n",
    "        if self._video_input:\n",
    "            self.video_info = self.inferencer.video_info\n",
    "\n",
    "        inputs = self.preprocess(\n",
    "            inputs, batch_size=batch_size, **preprocess_kwargs)\n",
    "\n",
    "        # forward\n",
    "        if 'bbox_thr' in self.inferencer.forward_kwargs:\n",
    "            forward_kwargs['bbox_thr'] = preprocess_kwargs.get('bbox_thr', -1)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for proc_inputs, ori_inputs in (track(inputs, description='Inference')\n",
    "                                        if self.show_progress else inputs):\n",
    "            preds = self.forward(proc_inputs, **forward_kwargs)\n",
    "\n",
    "            visualization = self.visualize(ori_inputs, preds,\n",
    "                                           **visualize_kwargs)\n",
    "            \n",
    "            results = self.postprocess(\n",
    "                preds,\n",
    "                visualization,\n",
    "                return_datasamples=return_datasamples,\n",
    "                **postprocess_kwargs)\n",
    "            \n",
    "            #MODIFIED START-----------------------------------\n",
    "            if kwargs[\"draw_heatmap\"] is True:\n",
    "                for batch_index in range(len(preds)):\n",
    "                    pred = preds[batch_index]\n",
    "                \n",
    "                    for person_index in range(len(pred.pred_instances)):\n",
    "                        person_pred = pred.pred_instances[person_index]\n",
    "                        \n",
    "                        results[\"predictions\"][batch_index][person_index][\"heatmaps\"] = pred._pred_heatmaps.heatmaps\n",
    "            #MODIFIED END-------------------------------------\n",
    "            \n",
    "            yield results\n",
    "\n",
    "        if self._video_input:\n",
    "            self._finalize_video_processing(\n",
    "                postprocess_kwargs.get('pred_out_dir', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.modified_call = MethodType(modified_call, inferencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_generator = inferencer.modified_call(img_path, draw_heatmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\mmpose\\models\\heads\\coord_cls_heads\\rtmcc_head.py:217: UserWarning: The predicted simcc values are normalized for visualization. This may cause discrepancy between the keypoint scores and the 1D heatmaps.\n",
      "  warnings.warn('The predicted simcc values are normalized for '\n"
     ]
    }
   ],
   "source": [
    "result = next(result_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = result[\"predictions\"][0][0][\"heatmaps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2552b380d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(heatmaps[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco2unity =   {\"nose\": 87, #nose\n",
    "               \"left_eye\": 80, #eye_left\n",
    "               \"right_eye\": 81, #eye_right\n",
    "               \"left_ear\": 85, #ear_left\n",
    "               \"right_ear\": 86, #ear_right\n",
    "               \"left_shoulder\": 21, #shoulder_left\n",
    "               \"right_shoulder\": 50, #shoulder_right\n",
    "               \"left_elbow\": 22, #elbow_left\n",
    "               \"right_elbow\": 51, #elbow_right\n",
    "               \"left_wrist\": 25, #wrist_left\n",
    "               \"right_wrist\": 54, #wrist_right\n",
    "               \"left_hip\": 88, #hip_left\n",
    "               \"right_hip\": 89, #hip_right\n",
    "               \"left_knee\": 2, #knee_left\n",
    "               \"right_knee\": 10, #knee_right\n",
    "               \"left_ankle\": 4, #ankle_left\n",
    "               \"right_ankle\": 12, #ankle_right\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "unity_labels = ['hip',\n",
    " 'leg_left',\n",
    " 'knee_left',\n",
    " 'accessories_ankle_left',\n",
    " 'ankle_left',\n",
    " 'foot_left',\n",
    " 'toes_left',\n",
    " 'lower_leg_left',\n",
    " 'upper_leg_left',\n",
    " 'leg_right',\n",
    " 'knee_right',\n",
    " 'accessories_ankle_right',\n",
    " 'ankle_right',\n",
    " 'foot_right',\n",
    " 'toes_right',\n",
    " 'lower_leg_right',\n",
    " 'upper_leg_right',\n",
    " 'spine_01',\n",
    " 'spine_02',\n",
    " 'spine_03',\n",
    " 'clavicle_left',\n",
    " 'shoulder_left',\n",
    " 'elbow_left',\n",
    " 'accessories_wrist_left',\n",
    " 'lower_arm_left',\n",
    " 'wrist_left',\n",
    " 'index_01_left',\n",
    " 'index_02_left',\n",
    " 'index_03_left',\n",
    " 'index_04_left',\n",
    " 'middle_01_left',\n",
    " 'middle_02_left',\n",
    " 'middle_03_left',\n",
    " 'middle_04_left',\n",
    " 'palm_left',\n",
    " 'pinky_01_left',\n",
    " 'pinky_02_left',\n",
    " 'pinky_03_left',\n",
    " 'pinky_04_left',\n",
    " 'ring_01_left',\n",
    " 'ring_02_left',\n",
    " 'ring_0',\n",
    " 'ring_03_left',\n",
    " 'ring_04_left',\n",
    " 'thumb_01_left',\n",
    " 'thumb_02_left',\n",
    " 'thumb_03_left',\n",
    " 'thumb_04_left',\n",
    " 'upper_arm_left',\n",
    " 'clavicle_right',\n",
    " 'shoulder_right',\n",
    " 'elbow_right',\n",
    " 'accessories_wrist_right',\n",
    " 'lower_arm_right',\n",
    " 'wrist_right',\n",
    " 'index_01_right',\n",
    " 'index_02_right',\n",
    " 'index_03_right',\n",
    " 'index_04_right',\n",
    " 'middle_01_right',\n",
    " 'middle_02_right',\n",
    " 'middle_03_right',\n",
    " 'middle_04_right',\n",
    " 'palm_right',\n",
    " 'pinky_01_right',\n",
    " 'pinky_02_right',\n",
    " 'pinky_03_right',\n",
    " 'pinky_04_right',\n",
    " 'ring_01_right',\n",
    " 'ring_02_right',\n",
    " 'ring_03_right',\n",
    " 'ring_04_right',\n",
    " 'thumb_01_right',\n",
    " 'thumb_02_right',\n",
    " 'thumb_03_right',\n",
    " 'thumb_04_right',\n",
    " 'upper_arm_right',\n",
    " 'neck',\n",
    " 'head',\n",
    " 'accessories_radix_nose',\n",
    " 'eye_left',\n",
    " 'eye_right',\n",
    " 'head_end',\n",
    " 'jaw',\n",
    " 'jaw_end',\n",
    " 'ear_left',\n",
    " 'ear_right',\n",
    " 'nose',\n",
    " 'hip_left',\n",
    " 'hip_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nose nose\n",
      "left_eye eye_left\n",
      "right_eye eye_right\n",
      "left_ear ear_left\n",
      "right_ear ear_right\n",
      "left_shoulder shoulder_left\n",
      "right_shoulder shoulder_right\n",
      "left_elbow elbow_left\n",
      "right_elbow elbow_right\n",
      "left_wrist wrist_left\n",
      "right_wrist wrist_right\n",
      "left_hip hip_left\n",
      "right_hip hip_right\n",
      "left_knee knee_left\n",
      "right_knee knee_right\n",
      "left_ankle ankle_left\n",
      "right_ankle ankle_right\n"
     ]
    }
   ],
   "source": [
    "for coco_label in coco2unity:\n",
    "    unity_index = coco2unity[coco_label]\n",
    "    unity_label = unity_labels[unity_index]\n",
    "\n",
    "    print(coco_label, unity_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
