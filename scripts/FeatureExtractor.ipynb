{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor\n",
    "\n",
    "This notebook extracts features (keypoints heatmaps) from dataset images.\n",
    "\n",
    "The extracted features are saved in \"<dataset_path>\\extracted_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the module imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob #Search files\n",
    "import json #JSON write\n",
    "import pathlib #Path things\n",
    "import os #Path things\n",
    "import warnings #Modified call\n",
    "from concurrent.futures import ThreadPoolExecutor #Threading\n",
    "from types import MethodType #Modified call\n",
    "from typing import Optional #Modified call\n",
    "\n",
    "import numpy as np #Array operations\n",
    "import imageio #EXR write\n",
    "import tqdm #Progress bar\n",
    "from rich.progress import track #Modified call\n",
    "import mmpose #Feature extractor\n",
    "from mmpose.apis import MMPoseInferencer #Feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of execution variables:\n",
    "- dataset_path: directory where the dataset is\n",
    "- batch_size: inference batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.environ[\"USERPROFILE\"]+\"\\\\AppData\\\\LocalLow\\\\DefaultCompany\\\\IA904-3D_Pose\\\\solo\"\n",
    "#dataset_path = \"I:\\\\.shortcut-targets-by-id\\\\1S6q0nt4z5LYa-5VkpC8qxag2b_jjO6e9\\\\IA904\\\\Dataset\"\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for all dataset images paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pattern = dataset_path+\"\\\\**\\\\*.png\"\n",
    "img_paths = glob.glob(search_pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes the feature extractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-body7_pt-body7_420e-256x192-e48f03d0_20230504.pth\n",
      "06/18 15:40:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpose\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpose\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "06/18 15:40:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    }
   ],
   "source": [
    "inferencer = MMPoseInferencer('human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencer custom \\_\\_call__\n",
    "\n",
    "Because the MMPose doesn't provide the infered heatmaps, the `__call__` method needs to be modified for returning it (only works for images with only one person, it will generate images with all detected heatmaps for the same keypoint if more than one person is in the image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base from MMPoseInferencer.__call__\n",
    "def modified_call(\n",
    "        self,\n",
    "        inputs: mmpose.apis.inferencers.mmpose_inferencer.InputsType,\n",
    "        return_datasamples: bool = False,\n",
    "        batch_size: int = 1,\n",
    "        out_dir: Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ) -> dict:\n",
    "        \"\"\"Call the inferencer.\n",
    "\n",
    "        Args:\n",
    "            inputs (InputsType): Inputs for the inferencer.\n",
    "            return_datasamples (bool): Whether to return results as\n",
    "                :obj:`BaseDataElement`. Defaults to False.\n",
    "            batch_size (int): Batch size. Defaults to 1.\n",
    "            out_dir (str, optional): directory to save visualization\n",
    "                results and predictions. Will be overoden if vis_out_dir or\n",
    "                pred_out_dir are given. Defaults to None\n",
    "            **kwargs: Key words arguments passed to :meth:`preprocess`,\n",
    "                :meth:`forward`, :meth:`visualize` and :meth:`postprocess`.\n",
    "                Each key in kwargs should be in the corresponding set of\n",
    "                ``preprocess_kwargs``, ``forward_kwargs``,\n",
    "                ``visualize_kwargs`` and ``postprocess_kwargs``.\n",
    "\n",
    "        Returns:\n",
    "            dict: Inference and visualization results.\n",
    "        \"\"\"\n",
    "        if out_dir is not None:\n",
    "            if 'vis_out_dir' not in kwargs:\n",
    "                kwargs['vis_out_dir'] = f'{out_dir}/visualizations'\n",
    "            if 'pred_out_dir' not in kwargs:\n",
    "                kwargs['pred_out_dir'] = f'{out_dir}/predictions'\n",
    "        \n",
    "        kwargs = {\n",
    "            key: value\n",
    "            for key, value in kwargs.items()\n",
    "            if key in set.union(self.inferencer.preprocess_kwargs,\n",
    "                                self.inferencer.forward_kwargs,\n",
    "                                self.inferencer.visualize_kwargs,\n",
    "                                self.inferencer.postprocess_kwargs)\n",
    "        }\n",
    "        (\n",
    "            preprocess_kwargs,\n",
    "            forward_kwargs,\n",
    "            visualize_kwargs,\n",
    "            postprocess_kwargs,\n",
    "        ) = self._dispatch_kwargs(**kwargs)\n",
    "\n",
    "        self.inferencer.update_model_visualizer_settings(**kwargs)\n",
    "\n",
    "        # preprocessing\n",
    "        if isinstance(inputs, str) and inputs.startswith('webcam'):\n",
    "            inputs = self.inferencer._get_webcam_inputs(inputs)\n",
    "            batch_size = 1\n",
    "            if not visualize_kwargs.get('show', False):\n",
    "                warnings.warn('The display mode is closed when using webcam '\n",
    "                              'input. It will be turned on automatically.')\n",
    "            visualize_kwargs['show'] = True\n",
    "        else:\n",
    "            inputs = self.inferencer._inputs_to_list(inputs)\n",
    "        self._video_input = self.inferencer._video_input\n",
    "        if self._video_input:\n",
    "            self.video_info = self.inferencer.video_info\n",
    "\n",
    "        inputs = self.preprocess(\n",
    "            inputs, batch_size=batch_size, **preprocess_kwargs)\n",
    "\n",
    "        # forward\n",
    "        if 'bbox_thr' in self.inferencer.forward_kwargs:\n",
    "            forward_kwargs['bbox_thr'] = preprocess_kwargs.get('bbox_thr', -1)\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for proc_inputs, ori_inputs in (track(inputs, description='Inference')\n",
    "                                        if self.show_progress else inputs):\n",
    "            preds = self.forward(proc_inputs, **forward_kwargs)\n",
    "\n",
    "            visualization = self.visualize(ori_inputs, preds,\n",
    "                                           **visualize_kwargs)\n",
    "            \n",
    "            results = self.postprocess(\n",
    "                preds,\n",
    "                visualization,\n",
    "                return_datasamples=return_datasamples,\n",
    "                **postprocess_kwargs)\n",
    "            \n",
    "            #MODIFIED START-----------------------------------\n",
    "            if kwargs[\"draw_heatmap\"] is True:\n",
    "                for batch_index in range(len(preds)):\n",
    "                    pred = preds[batch_index]\n",
    "                \n",
    "                    for person_index in range(len(pred.pred_instances)):\n",
    "                        person_pred = pred.pred_instances[person_index]\n",
    "                        \n",
    "                        results[\"predictions\"][batch_index][person_index][\"heatmaps\"] = pred._pred_heatmaps.heatmaps\n",
    "            #MODIFIED END-------------------------------------\n",
    "            \n",
    "            yield results\n",
    "\n",
    "        if self._video_input:\n",
    "            self._finalize_video_processing(\n",
    "                postprocess_kwargs.get('pred_out_dir', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.modified_call = MethodType(modified_call, inferencer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and save\n",
    "\n",
    "Now we just need to make the inference and save the extracted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder function for serializing numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    \n",
    "    return obj.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the inference generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_generator = inferencer.modified_call(img_paths, draw_heatmap=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the inferences and save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = ThreadPoolExecutor()\n",
    "\n",
    "def save_heatmaps(img_heatmaps, heatmaps_path):\n",
    "    np.savez_compressed(heatmaps_path, img_heatmaps=img_heatmaps)\n",
    "\n",
    "    #EXR export - More disk usage\n",
    "    #for keypoint_index in range(len(img_heatmaps)): #keypoints in person\n",
    "    #    keypoint_heatmap = img_heatmaps[keypoint_index]\n",
    "    #\n",
    "    #    heatmap_name = img_name+f\"_heatmap{person_index}_{keypoint_index}\"\n",
    "    #    heatmap_name += \".exr\"\n",
    "    #    heatmap_path = os.path.join(extrated_features_dir, heatmap_name)\n",
    "    #\n",
    "    #    imageio.imwrite(heatmap_path, keypoint_heatmap)\n",
    "\n",
    "def save_predictions(img_predictions, predictions_path):\n",
    "    file = open(predictions_path, \"w\")\n",
    "    json.dump(img_predictions, file, default=encoder)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19224 [00:00<?, ?it/s]c:\\Python38\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "c:\\Python38\\lib\\site-packages\\mmpose\\models\\heads\\coord_cls_heads\\rtmcc_head.py:217: UserWarning: The predicted simcc values are normalized for visualization. This may cause discrepancy between the keypoint scores and the 1D heatmaps.\n",
      "  warnings.warn('The predicted simcc values are normalized for '\n",
      "100%|██████████| 38448/38448 [00:00<00:00, 270754.73it/s]\n"
     ]
    }
   ],
   "source": [
    "futures = []\n",
    "\n",
    "pbar = tqdm.tqdm(total=len(img_paths))\n",
    "\n",
    "img_index = 0\n",
    "for result in result_generator: #batchs\n",
    "    predictions = result[\"predictions\"]\n",
    "\n",
    "    for batch_index in range(len(predictions)): #images in batch\n",
    "        img_result = predictions[batch_index]\n",
    "\n",
    "        img_path = img_paths[img_index] #Full image path\n",
    "        img_dir = os.path.dirname(img_path) #Image directory\n",
    "        img_name = os.path.splitext(os.path.basename(img_paths[img_index]))[0] #Image name without extension\n",
    "\n",
    "        inside_dir = os.path.relpath(img_dir, dataset_path) #Path of image without the dataset_path prefix\n",
    "        extrated_features_dir = os.path.join(dataset_path, \"extracted_features\", inside_dir) #Path of the image in the extracted_features dir\n",
    "        pathlib.Path(extrated_features_dir).mkdir(parents=True, exist_ok=True) #Create image path if not exists\n",
    "\n",
    "        if len(img_result) != 0:    \n",
    "            for person_index in [0]:#range(len(img_result)): #persons in image\n",
    "                img_heatmaps = predictions[batch_index][person_index][\"heatmaps\"]\n",
    "\n",
    "                heatmaps_name = img_name+\"_heatmaps\"\n",
    "                heatmaps_path = os.path.join(extrated_features_dir, heatmaps_name)\n",
    "\n",
    "                future = executor.submit(save_heatmaps, img_heatmaps, heatmaps_path)\n",
    "                futures.append(future)\n",
    "\n",
    "                img_predictions =  predictions[batch_index][person_index].copy()\n",
    "                del img_predictions[\"heatmaps\"]\n",
    "\n",
    "                predictions_name = img_name+\"_kp2d_predictions.json\"\n",
    "                predictions_path = os.path.join(extrated_features_dir, predictions_name)\n",
    "\n",
    "                future = executor.submit(save_predictions, img_predictions, predictions_path)\n",
    "                futures.append(future)\n",
    "                \n",
    "\n",
    "\n",
    "        pbar.update(1)\n",
    "        img_index += 1\n",
    "\n",
    "for future in tqdm.tqdm(futures):\n",
    "    future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference time: 1 h 19 min 42,8 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
